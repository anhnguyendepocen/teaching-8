
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Floating point error &#8212; Tutorials on imaging, computing and mathematics</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/copybutton.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The Fourier basis" href="fourier_basis.html" />
    <link rel="prev" title="Points on floats" href="floating_point.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <p><span class="math">\(\newcommand{L}[1]{\| #1 \|}\newcommand{VL}[1]{\L{ \vec{#1} }}\newcommand{R}[1]{\operatorname{Re}\,(#1)}\newcommand{I}[1]{\operatorname{Im}\, (#1)}\)</span></p>
<div class="section" id="floating-point-error">
<span id="floating-error"></span><h1>Floating point error<a class="headerlink" href="#floating-point-error" title="Permalink to this headline">¶</a></h1>
<p>This page maybe follows from <a class="reference internal" href="floating_point.html#floating-point"><span class="std std-ref">Points on floats</span></a></p>
<p>I ran into trouble trying to understand floating point error. After reading
<a class="reference external" href="http://en.wikipedia.org/wiki/Floating_point">Wikipedia floating point</a>, <a class="reference external" href="http://en.wikipedia.org/wiki/Machine_epsilon">Wikipedia machine epsilon</a> and <a class="reference external" href="http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html">What every
computer scientist should know about floating point</a>, I felt the need of some
more explanation, and so here it is.</p>
<div class="section" id="units-at-the-last-place">
<h2>Units at the last place<a class="headerlink" href="#units-at-the-last-place" title="Permalink to this headline">¶</a></h2>
<p>Taking the notation from <a class="reference external" href="http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html">Every computer scientist</a>; let’s imagine we have a
floating point number that has base 10 and 3 digits in the significand, say
$3.14 times 10^1$.  Because we only have 3 digits, the nearest larger number
that we can represent is obviously $3.15 times 10^1$.  This number differs from
$3.14 times 10^1$ by one unit in the last place (ULP).  Any real number $z$
that is between $3.14 times 10^1$ and $3.15 times 10^1$ can at best be
represented with one of these two numbers.  Let’s say $z$ is actually $pi$; now
$3.1415926…$ is best represented in our numbers as $3.14 times 10^1$, and the
rounding error is $pi - 3.14 times 10^1 = 0.0015926…$  In the worst case, we
could have some real number $3.145 times 10^1$ that will have rounding error
0.005.  If we always choose the floating point number nearest to our real number
$z$ then the maximum rounding error occurs when $z$ is halfway between two
representable numbers; in that case the rounding error is 0.5 ULP.</p>
<p>We can generalize to floating point numbers of form:</p>
<div class="math">
\[d_1.d_2...d_p \times \beta^e\]</div>
<p>Where $p$ is the number of digits in the significand, $beta$ is the <em>base</em> (10
in our example), and $e$ is the exponent.</p>
<p>1 ULP corresponds to:</p>
<div class="math">
\[0.00...1 \times \beta^e\]</div>
<p>where there are $p-1$ zeros in the significand. This is also:</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Normalized representation in floating point</p>
<p>Short version: The floating point representation of a number is <em>normalized</em>
if $d_1$ is not zero.</p>
<p class="last">Long version: consider the number 1.00 represented in the $p = 3, beta=10$
system that we started with.  We can represent this number as $1.00 times
10^0$ or $0.10 times 10^1$ or $0.01 times 10^2$.  The <em>normalized</em>
representation is the representation with a non-zero first digit - $1.00
times 10^0$ in this case. There is only one normalized representation of a
number in a particular floating point representation, so a normalized
representation is unique.</p>
</div>
<div class="math">
\[1.0 \times \beta^{e-(p-1)}\]</div>
<p>Note that any normalized floating point number with exponent $e$ has the same
value for 1 ULP.  Let’s define:</p>
<div class="math">
\[ulp(e, p) \to \beta^{e-(p-1)}\]</div>
<p>We can represent any real number $x$ in normalized floating point format by
using an infinite significand:</p>
<div class="math">
\[d_1.d_2... \times \beta^e\]</div>
<p>Again, <em>normalized</em> means that $d_1 ne 0$.  The ULP value for a real value $x$
in some some finite floating point format is still $ulp(e, p)$ where $p$ is the
number of digits in the significand as above.</p>
</div>
<div class="section" id="absolute-error">
<h2>Absolute error<a class="headerlink" href="#absolute-error" title="Permalink to this headline">¶</a></h2>
<p>The IEEE standard for floating point specifies that the result of any floating
point operation should be correct to within the rounding error of the resulting
number.  That is, it specifies that the maximum rounding error for an individual
operation (add, multiply, subtract, divide) should be 0.5 ULP.</p>
<p>In practice it’s now very hard indeed to find a machine that does not implement
this rule for floating point operations.</p>
<p>Imagine we have two finite floating point numbers $q$ and $r$ and we combine
them using one of the operators {<code class="docutils literal"><span class="pre">+,</span> <span class="pre">-,</span> <span class="pre">*,</span> <span class="pre">/</span></code>} in a perfect world at infinite
precision:</p>
<div class="math">
\[x = q \circ r\]</div>
<p>where $circ$ is one of the operators {<code class="docutils literal"><span class="pre">+,</span> <span class="pre">-,</span> <span class="pre">*,</span> <span class="pre">/</span></code>}. Let’s call the actual
finite precision number returned from this calculation $fl(x)$.  The IEEE
standard specifies that $fl(x)$ should be the closest number to $x$ that can be
represented in the finite precision format.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>What is the floating point exponent for any given real number?</p>
<p>So far we’ve assumed that we know the representation of our floating point
number in terms of significand and exponent.</p>
<p>But — what if we have a some infinite precision number $x$ and we want to
know how to represent it in floating point?</p>
<p>A simple algorithm might be to get the exponent by an algorithm like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">e1</span> <span class="o">=</span> <span class="n">logB</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="n">exponent</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">e1</span><span class="p">)</span>
</pre></div>
</div>
<p>Where $abs(y)$ gives the absolute value of $y$, $logB(y)$ is the log to base
$beta$, and $floor(y)$ gives the most positive integer $i$, such that $i &lt;=
y$ <a class="footnote-reference" href="#floor" id="id1">[1]</a>.</p>
<p>We can then get the mantissa part with $round(x / beta^{e2}, p-1)$, where
$round(y, z)$ rounds the number $y$ to $z$ digits after the decimal point.</p>
<p>Worked example in Python with our original system of $p = 3, beta = 10$:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="nb">abs</span><span class="p">,</span> <span class="n">log10</span><span class="p">,</span> <span class="n">floor</span><span class="p">,</span> <span class="nb">round</span>
<span class="n">x</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.1234</span> <span class="c1"># a number with greater precision than format allows</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># number of digits in mantissa</span>
<span class="n">x1</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 0.1234</span>
<span class="n">e1</span> <span class="o">=</span> <span class="n">log10</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="c1"># -0.9086848403027772</span>
<span class="n">exponent</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">e1</span><span class="p">)</span> <span class="c1"># -1</span>
<span class="n">m1</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10</span> <span class="o">**</span> <span class="n">e2</span><span class="p">)</span> <span class="c1"># -1.234</span>
<span class="n">mantissa</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># -1.23</span>
</pre></div>
</div>
<p>giving $-1.23 times 10^{-1}$ as the floating point representation.</p>
<p class="last">For full accuracy, the algorithm has to be a little more sophisticated than
this, but this is a reasonable first pass <a class="footnote-reference" href="#fancy-rounding" id="id2">[2]</a>.</p>
</div>
<p>We remember that $p$ is the number of digits in the significand in our finite
floating point format. The IEEE rule then becomes:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\left| fl(x) - x \right| \le 0.5 \times ulp(e, p)\\\left| fl(x) - x \right| \le 0.5 \times \beta^{e-(p-1)}\end{aligned}\end{align} \]</div>
</div>
<div class="section" id="relative-error">
<h2>Relative error<a class="headerlink" href="#relative-error" title="Permalink to this headline">¶</a></h2>
<p>The <em>relative error</em> is the rounding error divided by the infinite precision
real number $x$:</p>
<div class="math">
\[\left| \frac{fl(x) - x}{x} \right| \le \frac{0.5 \times \beta^{e-(p-1)}}{x}\]</div>
<p>However, any value for $x$ that has some exponent $e$ has the same value for
$ulp(e, p) = beta^{e-(p-1)}$.  Let $m$ be the largest digit in base $beta$;
thus $m = beta - 1$.  For example $m = 9$ in base 10 ($beta = 10$). The values
of $x$ between $1.0 times beta^e$ and $m.mmm… times beta^e$ all have the
same value for 1 ULP = $beta^{e-(p-1)}$. The <em>relative</em> rounding error will be
greater for smaller $x$ with the same exponent.  Let:</p>
<div class="math">
\[ \begin{align}\begin{aligned}a = 0.5 \times ulp(e, p).\\a = 0.5 \times \beta^{e-(1-p)}\end{aligned}\end{align} \]</div>
<p>Make $x$ the smallest value with this exponent that has a large rounding error:</p>
<div class="math">
\[x = 1.0 \times \beta^e + a\]</div>
<p>The relative rounding error $epsilon$ is:</p>
<div class="math">
\[\epsilon = \frac{a}{\beta^e + a}\]</div>
<p>Because $a$ is very small compared to $beta^e$:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\epsilon \approx \frac{0.5 \times \beta^{e-(p-1)}}{\beta^e}\\\epsilon \approx 0.5 \times \beta^{1-p}\end{aligned}\end{align} \]</div>
<p>Now make $x$ the largest value with this exponent and that has a large rounding
error:</p>
<div class="math">
\[ \begin{align}\begin{aligned}x = m.mm... \times \beta^e - a\\x \approx 1.0 \times \beta^{e+1} - a\end{aligned}\end{align} \]</div>
<p>then:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\epsilon \approx \frac{a}{\beta^{e+1} - a}\\\epsilon \approx \frac{0.5 \times \beta^{e-(p-1)}}{\beta^{e+1}}\\\epsilon \approx 0.5 \times \beta^{-p}\end{aligned}\end{align} \]</div>
<p>So, the <em>maximum</em> relative error for $x$ varies (depending on the value of $x$)
between $approx 0.5 times beta^{-p}$ and $approx 0.5 times beta^{1-p}$.</p>
<p>Therefore the relative error for any $x$ (regardless of exponent) is bounded by
the larger of these two maxima:</p>
<div class="math">
\[\epsilon \le 0.5 \times \beta^{1-p}\]</div>
</div>
<div class="section" id="machine-epsilon">
<h2>Machine epsilon<a class="headerlink" href="#machine-epsilon" title="Permalink to this headline">¶</a></h2>
<p>Now note that $beta^{1-p}$ is the ULP for 1; that is $1.0 times
beta^{e-(p-1)}$ where $e$ is 0.  Some people refer to this value as <em>machine
epsilon</em>, others use that term for $0.5 times beta^{1-p}$ - see <a class="reference external" href="http://en.wikipedia.org/wiki/Machine_epsilon#Variant_definitions">variant
definitions</a>.  MATLAB and Octave return $beta^{1-p}$ from their <code class="docutils literal"><span class="pre">eps()</span></code>
function. <a class="reference external" href="http://www.numpy.org">numpy</a> uses the same convention in its <code class="docutils literal"><span class="pre">np.finfo</span></code> function.  For
example, the standard <code class="docutils literal"><span class="pre">float64</span></code> double precision type in numpy has $beta = 2;
p=53$:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span> <span class="o">==</span> <span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mi">53</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</div>
<div class="section" id="thanks-to">
<h2>Thanks to<a class="headerlink" href="#thanks-to" title="Permalink to this headline">¶</a></h2>
<p>Stefan van der Walt for several useful suggestions and corrections.</p>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="floor" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>See <a class="reference external" href="http://en.wikipedia.org/wiki/Floor_and_ceiling_functions">Wikipedia floor / ceiling functions</a>. The floor function here
(and in C and Python and the Wikipedia page) returns the integer closest to
negative infinity.  For example, <code class="docutils literal"><span class="pre">floor(1.9)</span> <span class="pre">==</span> <span class="pre">1</span></code>, <code class="docutils literal"><span class="pre">floor(-1.1)</span> <span class="pre">==</span>
<span class="pre">-2</span></code>.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="fancy-rounding" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>To find the exact closest floating point representation of
a given number, we have to take into account that large values with exponent $e$
may in fact be closer to $1 times beta^{e+1}$. For example, with $p=3,
beta=10$, the infinite precision value $9.996$ is closer to $1.00 times 10^1$
than $9.99 times 10^0$, even though <code class="docutils literal"><span class="pre">floor(log10(9.996))</span> <span class="pre">==</span> <span class="pre">0</span></code>.</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Floating point error</a><ul>
<li><a class="reference internal" href="#units-at-the-last-place">Units at the last place</a></li>
<li><a class="reference internal" href="#absolute-error">Absolute error</a></li>
<li><a class="reference internal" href="#relative-error">Relative error</a></li>
<li><a class="reference internal" href="#machine-epsilon">Machine epsilon</a></li>
<li><a class="reference internal" href="#thanks-to">Thanks to</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="floating_point.html" title="previous chapter">Points on floats</a></li>
      <li>Next: <a href="fourier_basis.html" title="next chapter">The Fourier basis</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/floating_error.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Matthew Brett.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/floating_error.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>